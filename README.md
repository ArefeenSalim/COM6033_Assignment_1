# Reflection

## Design and implementation
### - A supervised regression approach was selected because the task involves predicting a continuous numerical value, namely the sale price of UK residential properties, using historical transaction data where the target value is known.
### - Linear regression was implemented as a baseline model to establish an initial performance benchmark and to provide a clear, interpretable starting point for understanding relationships between features and property prices.
### - To improve model performance and address limitations of the baseline model, Ridge regression and Lasso-style regularisation were introduced. These models were chosen to reduce the impact of multicollinearity and overfitting caused by the large number of features generated through one-hot encoding of categorical variables such as property type, tenure, and county.
### - A ColumnTransformer was used to apply appropriate preprocessing steps to different feature types, including one-hot encoding for categorical variables and standardisation for numerical features such as year and month. This ensured that all input features were in a suitable format for model training.
### - Pipelines were used to combine preprocessing and model training into a single workflow. This approach reduced the risk of data leakage and ensured that the same preprocessing steps were applied consistently during training and when making predictions in the deployed application.
### - The final model was saved using joblib and integrated into a Flask web application, enabling users to input property details and receive price predictions, demonstrating the practical implementation of the trained machine learning model.

## Challenges Encountered 
### One of the main challenges encountered during this project was working with the size and structure of the UK Land Registry dataset. The data was provided across multiple CSV files and contained a very large number of records, which required careful handling to avoid performance and memory issues. Combining the files into a single dataset while maintaining data integrity was an important initial step before any further analysis could take place.
### Another challenge involved cleaning and preparing the data for machine learning. The dataset contained a mixture of numerical, categorical, and administrative fields, many of which were not directly useful for predicting property prices. Identifying which features to retain and which to remove required careful inspection of the dataset and an understanding of the problem domain. In addition, several variables, including prices and dates, were initially stored as strings and needed to be converted into appropriate numerical formats before modelling could begin.
### A further challenge was dealing with the highly skewed distribution of property prices. Extremely large price values made it difficult for regression models to perform effectively, which required the application of a logarithmic transformation to stabilise the distribution. Finally, deploying the trained model into a Flask web application introduced additional complexity, particularly in ensuring that user inputs were correctly mapped to the format expected by the model and that preprocessing steps remained consistent between training and prediction.

## Model Evaluation
### Model performance was assessed using Variance (R^2), Mean Absolute Error (MAE), and Root Mean Squared Error (RMSE). These metrics were chosen because they provide complementary insights into how well the model explains variance in property prices and the typical size of prediction errors.
### The baseline linear regression model achieved reasonable performance, demonstrating that a linear relationship exists between the selected features and property prices. This confirmed that the chosen features were suitable for prediction.
### Ridge regression consistently produced the strongest results across the evaluation metrics. The improvement in performance indicates that regularisation helped stabilise the model and reduce the impact of correlated features introduced through categorical encoding.
### The Lasso-style model was effective in controlling model complexity but did not outperform Ridge regression, suggesting that shrinking coefficients while retaining all features was more beneficial than enforcing sparsity for this dataset.
### Evaluation results were consistent with the behaviour observed in the deployed Flask application, where the Ridge regression model generated stable and realistic price estimates for a range of user inputs.

## Future Improvements 
### The Flask web application could be extended to support more detailed location inputs, such as town or district, rather than only county level information. These features were removed during model development due to their very high number of unique values, which significantly increased model dimensionality and complexity. In future work, encoding based on average regional prices could be applied to allow precise location input within the app without negatively impacting performance.
### The current application accepts a limited set of user inputs in order to keep the interface simple and user-friendly. If additional property data were available, the app could be expanded to include property size, number of bedrooms, or radius, which would likely improve prediction accuracy.
### From a usability perspective, the application could be enhanced by providing clearer input validation and guidance within the user interface, ensuring that user submissions are consistent and reducing the likelihood of invalid input values.
### future development could involve deploying the application to a public cloud platform, allowing the system to be accessed more widely and better reflecting how machine learning models are typically delivered in real-world environments.